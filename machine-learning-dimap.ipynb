{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIM0782 - Machine Learning (DIMAp/UFRN/2024.1)\n",
    "\n",
    "## Preprocessing the data\n",
    "\n",
    "### Transforming non-structured data to structured data\n",
    "\n",
    "This is textual data, so the first step is to turn it into structured data by applying a transformer. I'm going to work mostly with BERT here.\n",
    "\n",
    "First, I'm going to define the imports block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reading the sentiments dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df = pd.read_csv(\"datasets/twitter_sentiment_base_original.csv\", usecols=[\"text\", \"label\"])\n",
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating a Shorter Dataset (Optional Step)\n",
    "-- -------------------------\n",
    "\n",
    "This might be helpful in case your base is originally too big to be processed on a reasonable time for this exercise. Running this block would still allow you to run the subsequent blocks of code with no issues. You can totally skip this step as well in case you have the computing power to process the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size, random_state = 4000, 42\n",
    "sampled_data = []\n",
    "\n",
    "for i in range(6): ## Since we have 6 sentimens, labeled from 0 to 5\n",
    "    sampled_data.append(sentiments_df[sentiments_df['label'] == i].sample(n=sample_size, random_state=random_state))\n",
    "\n",
    "sentiments_df = pd.concat(sampled_data)\n",
    "sentiments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- ----------\n",
    "### End of Optional Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to utilize a BERT tokenizer to transform the text data that I have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the pretrained model and tokenizer\n",
    "tokenizer = (ppb.DistilBertTokenizer).from_pretrained('distilbert-base-uncased')\n",
    "model = (ppb.DistilBertModel).from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "## Tokenizing w/ BERT\n",
    "sentiments_tokenized = sentiments_df[\"text\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above outputs the tokenized data with rows of different sizes, since each sentence has a different length. We now need to apply a process called padding in order to make all of the sentences with equal size. We will also need an attention mask, which will tell BERT which rows he should consider the data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating a new dataframe with the tokenized data appended with their associated labels\n",
    "biggest_sentence_length = 0\n",
    "for i in sentiments_tokenized.values:\n",
    "    if len(i) > biggest_sentence_length:\n",
    "        biggest_sentence_length = len(i)\n",
    "\n",
    "## Getting the values padded and the attention mask\n",
    "sentiments_tokenized_padded = np.array([i + [0]*(biggest_sentence_length-len(i)) for i in sentiments_tokenized.values])\n",
    "attention_mask = np.where(sentiments_tokenized_padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're finally going to process those input IDs that we generated on the steps above and we will generate the actual BERT embeddings. Given the size of the dataset, I ran multiple tests and realized that memory would be an issue. I need to split this into batches and work from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(sentiments_tokenized_padded)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "batch_size = 4000      # Change it as it is necessary \n",
    "all_hidden_states = [] # BERT generates what we call hidden states\n",
    "\n",
    "def batch_generator(input_ids, attention_mask, batch_size):\n",
    "    for i in range(0, len(input_ids), batch_size):\n",
    "        yield input_ids[i:i+batch_size], attention_mask[i:i+batch_size]\n",
    "\n",
    "## Processes the input over batches through the help of a generator\n",
    "with torch.no_grad():\n",
    "    for batch_ids, batch_mask in batch_generator(input_ids, attention_mask, batch_size):\n",
    "        outputs = model(batch_ids, attention_mask=batch_mask)\n",
    "        all_hidden_states.append(outputs.last_hidden_state)\n",
    "\n",
    "## Concatenates all batch results\n",
    "last_hidden_states = torch.cat(all_hidden_states, dim=0)\n",
    "torch.save(last_hidden_states, 'tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states = torch.load('datasets/tensor.pt')\n",
    "sentiments_features = last_hidden_states[:,0,:].numpy()\n",
    "labels = sentiments_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also going to develop this auxiliary block that will be able to save my dataset with the n-dimension features I generate as a result from applying the techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_to_csv(features, labels, filename):\n",
    "    df = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(features.shape[1])])\n",
    "    df['label'] = labels.to_numpy()\n",
    "    \n",
    "    df.to_csv(filename, index=False)    \n",
    "\n",
    "## This is the line that will change depending on the file I want to generate\n",
    "features_to_csv(sentiments_features, labels, 'datasets/twitter_sentiment_base_ready.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction of Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of this work, it is required to reduce instances on my dataset.\n",
    "\n",
    "The first dataset I was working with had about 400000 records, and I could not process the embeddings and tokenization on a timely manner. I had to do a brusk reduction on the size, so now I don't have a dataset that is that big. My goal here is just to get some sampling of 80% of the already reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables for the sampling conditions\n",
    "sample_size, random_state = 3200, 42\n",
    "sampled_data = []\n",
    "sentiments_processed_df = pd.read_csv('datasets/twitter_sentiment_base_ready.csv')\n",
    "\n",
    "for i in range(6): ## Since we have 6 sentimens, labeled from 0 to 5\n",
    "    sampled_data.append(sentiments_processed_df[sentiments_processed_df['label'] == i].sample(n=sample_size, random_state=random_state))\n",
    "\n",
    "sampled_sentiments_df = pd.concat(sampled_data)\n",
    "sampled_sentiments_df.to_csv('datasets/twitter_sentiments_base_sampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute selection (w/ Decision Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are quite useful for the purpose of doing attribute (or feature) selection because they inherently perform feature selection by splitting nodes based on the most informative features. By using a decision tree, we can identify which attributes (or features) contribute most to predicting the output, making it a practical approach for reducing dimensionality and improving model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sentiments_embeddings_train, sentiments_embeddings_test, sentiments_labels_train, sentiments_labels_test = train_test_split(sentiments_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "decision_tree.fit(sentiments_embeddings_train, sentiments_labels_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = decision_tree.feature_importances_\n",
    "\n",
    "# Now we sort the importances on descending order and select the top X features - (X: originally 50)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_features = indices[:50]\n",
    "\n",
    "# Finally, we select only the top features that were applied\n",
    "sentiments_embeddings_train_reduced = sentiments_embeddings_train[:, top_features]\n",
    "sentiments_embeddings_test_reduced = sentiments_embeddings_test[:, top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm adding this auxiliary block here for merging the results back to a single sentiments embeddings array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_embeddings_decision_tree = np.concatenate((sentiments_embeddings_train_reduced, sentiments_embeddings_test_reduced))\n",
    "sentiments_embeddings_decision_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Attribute selection using Decision Tree\")\n",
    "plt.bar(range(sentiments_embeddings_train_reduced.shape[1]), importances[top_features], align='center')\n",
    "plt.xticks(range(sentiments_embeddings_train_reduced.shape[1]), top_features, rotation=90)\n",
    "plt.xlim([-1, sentiments_embeddings_train_reduced.shape[1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "Running Principal Component Analysis (PCA) is a powerful method to reduce the dimensionality of our data while retaining as much variability as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sentiments_features_scaled = scaler.fit_transform(sentiments_features)\n",
    "\n",
    "# Choose the number of components (example: reduce dimensions to keep 95% of the variance)\n",
    "pca = PCA(n_components=0.95)\n",
    "sentiments_pca = pca.fit_transform(sentiments_features_scaled)\n",
    "\n",
    "print(f\"Number of components kept: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine the explained variance of the PCA. This will tell us how much information (variability) was retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance by each component: {explained_variance}\")\n",
    "print(f\"Total variance explained: {sum(explained_variance)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now finally visualize the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(range(1, 215), pca.explained_variance_ratio_, marker='o', linestyle='--')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scree plot generated is a graphical representation of the variance explained by each principal component the analysis.\n",
    "\n",
    "The x-axis represents the number of principal components. In the plot, it ranges from 1 to over 200.\n",
    "The y-axis represents the variance explained by each principal component. It shows the proportion of the dataset’s total variance.\n",
    "Elbow Method: Typically, the goal of a scree plot is to identify the 'elbow' of the graph, which indicates the point at which the variance explained by each additional component drops off and becomes minimal. This point is considered a good cut-off for reducing the number of components because beyond this point, you're getting diminishing returns on explained variance.\n",
    "\n",
    "In our plot, there is a steep drop after the first few components, then the decline slows significantly. This suggests that the first few components capture a substantial amount of the information (variance) in the dataset. After this initial steep drop, the plot levels off around the 40-component mark, indicating that each additional component contributes less and less.\n",
    "\n",
    "It’s worth noting that the first component explains significantly more variance than the subsequent ones. In practical terms, this could mean that there is one dominant feature or pattern in your data that accounts for most of the variance, with each additional feature contributing less to explaining the dataset.\n",
    "\n",
    "Based on this plot, we might consider retaining only the components before the curve starts to flatten if you aim to reduce dimensionality while retaining most of the information.\n",
    "\n",
    "That's why I'm going to run the PCA algorithm again, but changing the n parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_round_two = PCA(n_components=0.70)\n",
    "sentiments_pca = pca_round_two.fit_transform(sentiments_features_scaled)\n",
    "\n",
    "print(f\"Number of components kept: {pca_round_two.n_components_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate this scree plot again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(range(1, 30), pca_round_two.explained_variance_ratio_, marker='o', linestyle='--')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression\n",
    "\n",
    "Given that the dataset has 6 possible sentiments (labels), it won't be possible to run Logistic Regression (because the data decision is not binary). Because of that, we can investigate the behavior of applying a multinomial logistic regression classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Percentage test split method - can adjust percentage\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Invoking the logistic regression model\n",
    "logistic_regression_sentiments = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1500)\n",
    "\n",
    "logistic_regression_sentiments.fit(train_features, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic_regression_sentiments.predict(test_features)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us implement the k-Nearest Neighbors algorithm and understand how it behaves with our sentiments dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Percentage test split method - can adjust percentage\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the KNN model with a specified number of neighbors; e.g., k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually run the kNN Algorithm, with the parameters adjusted as above. This version comprehends the percentage test split, but I'll also show it using the 10-fold cross validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "knn.fit(train_features, train_labels)\n",
    "\n",
    "# Predicting the test set\n",
    "labels_predict = knn.predict(test_features)\n",
    "\n",
    "print(\"Accuracy of kNN (5 neighbors, 70/30 split):\", accuracy_score(test_labels, labels_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kNN via the 10-fold cross-validation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Create the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Prepare to collect accuracy scores\n",
    "accuracies = []\n",
    "\n",
    "knn_labels = np.array(labels)\n",
    "\n",
    "# Perform 10-fold CV\n",
    "for train_index, test_index in kf.split(sentiments_features):\n",
    "    sentiments_train, sentiments_test = sentiments_features[train_index], sentiments_features[test_index]\n",
    "    labels_train, labels_test = knn_labels[train_index], knn_labels[test_index]\n",
    "\n",
    "    # Train the kNN Model inside the current fold\n",
    "    knn.fit(sentiments_train, labels_train)\n",
    "\n",
    "    # Predict and evaluate the model\n",
    "    labels_predict = knn.predict(sentiments_test)\n",
    "    accuracy = accuracy_score(labels_test, labels_predict)\n",
    "    accuracies.append(accuracy)\n",
    "    print(\"Accuracy from this fold:\", accuracy)\n",
    "\n",
    "# Calculate and print the average accuracy and standard deviation\n",
    "print(\"Average accuracy:\", np.mean(accuracies))\n",
    "print(\"Standard deviation of accuracy:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "Implementing the Decision Tree Classifier and varying its max depth to compare accuracy. This is using the percentage split method of collecting the data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Percentage test split method - can adjust percentage\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the Decision Tree Classifier (DTC) model with a specified max depth; e.g., md =5\n",
    "dtc = DecisionTreeClassifier(max_depth=7, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "dtc.fit(train_features, train_labels)\n",
    "\n",
    "# Predicting the test set\n",
    "labels_predict = dtc.predict(test_features)\n",
    "\n",
    "print(\"Accuracy of Decision Tree Classifier (5 Max-Depth, 70/30 split):\", accuracy_score(test_labels, labels_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implementing it via the 10-fold cross-validation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Create the Decision Tree Classifier (DTC) model with a specified max depth; e.g., md =5\n",
    "dtc = DecisionTreeClassifier(max_depth=7, random_state=42)\n",
    "\n",
    "# Prepare to collect accuracy scores\n",
    "accuracies = []\n",
    "\n",
    "dtc_labels = np.array(labels)\n",
    "\n",
    "# Perform 10-fold CV\n",
    "for train_index, test_index in kf.split(sentiments_features):\n",
    "    sentiments_train, sentiments_test = sentiments_features[train_index], sentiments_features[test_index]\n",
    "    labels_train, labels_test = dtc_labels[train_index], dtc_labels[test_index]\n",
    "\n",
    "    # Train the DTC Model inside the current fold\n",
    "    dtc.fit(sentiments_train, labels_train)\n",
    "\n",
    "    # Predict and evaluate the model\n",
    "    labels_predict = dtc.predict(sentiments_test)\n",
    "    accuracy = accuracy_score(labels_test, labels_predict)\n",
    "    accuracies.append(accuracy)\n",
    "    print(\"Accuracy from this fold:\", accuracy)\n",
    "\n",
    "# Calculate and print the average accuracy and standard deviation\n",
    "print(\"Average accuracy:\", np.mean(accuracies))\n",
    "print(\"Standard deviation of accuracy:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "Implementing the Gaussian Naive Bayes classifier. Parameters are priors = 0 (array of prior probabilities) and var_smoothing: 1e-9, as per the professor's specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Percentage test split method - can adjust percentage\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create the Gaussian Naive Bayes (GNB) model\n",
    "gnb = GaussianNB(priors=None, var_smoothing=1e-9)\n",
    "\n",
    "# Training the model\n",
    "gnb.fit(train_features, train_labels)\n",
    "\n",
    "# Predicting the test set\n",
    "labels_predict = gnb.predict(test_features)\n",
    "\n",
    "print(\"Accuracy of Gaussian Naive Bayes:\", accuracy_score(test_labels, labels_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the 10-fold cross-validation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Create the Decision Tree Classifier (DTC) model with a specified max depth; e.g., md =5\n",
    "gnb = GaussianNB(priors=None, var_smoothing=1e-9)\n",
    "\n",
    "# Prepare to collect accuracy scores\n",
    "accuracies = []\n",
    "\n",
    "gnb_labels = np.array(labels)\n",
    "\n",
    "# Perform 10-fold CV\n",
    "for train_index, test_index in kf.split(sentiments_features):\n",
    "    sentiments_train, sentiments_test = sentiments_features[train_index], sentiments_features[test_index]\n",
    "    labels_train, labels_test = gnb_labels[train_index], gnb_labels[test_index]\n",
    "\n",
    "    # Train the GNB Model inside the current fold\n",
    "    gnb.fit(sentiments_train, labels_train)\n",
    "\n",
    "    # Predict and evaluate the model\n",
    "    labels_predict = gnb.predict(sentiments_test)\n",
    "    accuracy = accuracy_score(labels_test, labels_predict)\n",
    "    accuracies.append(accuracy)\n",
    "    print(\"Accuracy from this fold:\", accuracy)\n",
    "\n",
    "# Calculate and print the average accuracy and standard deviation\n",
    "print(\"Average accuracy:\", np.mean(accuracies))\n",
    "print(\"Standard deviation of accuracy:\", np.std(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP)\n",
    "\n",
    "The Multilayer Perceptron (MLP) is a type of artificial neural network that is widely used for solving complex pattern recognition and classification problems. It belongs to a larger class of feedforward neural networks and consists of at least three layers of nodes: an input layer, one or more hidden layers, and an output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Percentage test split method - can adjust percentage\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Calculate the neurons configuration, based on requirements provided by the professor\n",
    "a_value = 387 # 768 attributes and 6 classes (sentiments)\n",
    "neurons = [a_value - 50, a_value, a_value + 50]\n",
    "accuracies = []\n",
    "\n",
    "# Loop through neuron configurations\n",
    "for neuron in neurons:\n",
    "    print(\"Starting the classifier for neurons amount:\", neuron)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(neuron,), max_iter=300, activation='relu', solver='adam', random_state=42)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    labels_predict = mlp.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, labels_predict)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(neurons, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('MLP Accuracy vs. Number of Neurons')\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to take the number of neurons that we found on the previous experiment, and run the classifier again, but varying the max iterations parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Percentage test split method - can adjust percentage\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initiate the values needed\n",
    "accuracies = []\n",
    "iterations = [300, 1000, 5000]\n",
    "best_neuron_length = 437\n",
    "\n",
    "# Loop through neuron configurations\n",
    "for iteration in iterations:\n",
    "    print(\"Starting the classifier for neurons iterations amount:\", iteration)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_neuron_length,), max_iter=iteration, activation='relu', solver='adam', random_state=42)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    labels_predict = mlp.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, labels_predict)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('MLP Accuracy vs. Number of Iterations')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with all of that information, we're going to adjust the learning rate parameter changes, to look for the best configuration available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Percentage test split method - can adjust percentage\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initiate the values needed\n",
    "accuracies = []\n",
    "best_max_iter = 300\n",
    "best_neuron_length = 437\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "\n",
    "# Loop through neuron configurations\n",
    "for learning_rate in learning_rates:\n",
    "    print(\"Starting the classifier for learning rate amount:\", learning_rate)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(best_neuron_length,), learning_rate_init=learning_rate, max_iter=best_max_iter, activation='relu', solver='adam', random_state=42)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    labels_predict = mlp.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, labels_predict)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('MLP Accuracy vs. Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Calculate the neurons configuration, based on requirements provided by the professor\n",
    "a_value = 387 # 768 attributes and 6 classes (sentiments)\n",
    "neurons = [a_value - 50, a_value, a_value + 50]\n",
    "accuracies = []\n",
    "\n",
    "# Perform 10-fold CV for each neuron that I'm evaluating\n",
    "for neuron in neurons:\n",
    "    print(\"Entering neuron amount of:\", neuron)\n",
    "    local_accuracy_average = []\n",
    "    for train_index, test_index in kf.split(sentiments_features):\n",
    "        sentiments_train, sentiments_test = sentiments_features[train_index], sentiments_features[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(neuron,), max_iter=300, activation='relu', solver='adam', random_state=42)\n",
    "        mlp.fit(sentiments_train, labels_train)\n",
    "        labels_predict = mlp.predict(sentiments_test)\n",
    "        local_accuracy_average.append(accuracy_score(labels_test, labels_predict))\n",
    "    print(\"Processed neurons with 10-fold cross-validation, average accuracy:\", np.mean(local_accuracy_average))\n",
    "    accuracies.append(np.mean(local_accuracy_average))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(neurons, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('MLP Accuracy vs. Number of Neurons (10-fold CV)')\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with all of that information, we're going to adjust the learning rate parameter changes, to look for the best configuration available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Calculate the neurons configuration, based on requirements provided by the professor\n",
    "iterations = [300, 1000, 5000]\n",
    "best_neuron_length = 387\n",
    "accuracies = []\n",
    "\n",
    "# Perform 10-fold CV for each neuron that I'm evaluating\n",
    "for iteration in iterations:\n",
    "    print(\"Entering iteration amount of:\", iteration)\n",
    "    local_accuracy_average = []\n",
    "    for train_index, test_index in kf.split(sentiments_features):\n",
    "        sentiments_train, sentiments_test = sentiments_features[train_index], sentiments_features[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(best_neuron_length,), max_iter=iteration, activation='relu', solver='adam', random_state=42)\n",
    "        mlp.fit(sentiments_train, labels_train)\n",
    "        labels_predict = mlp.predict(sentiments_test)\n",
    "        local_accuracy_average.append(accuracy_score(labels_test, labels_predict))\n",
    "    print(\"Processed iteration with 10-fold cross-validation, average accuracy:\", np.mean(local_accuracy_average))\n",
    "    accuracies.append(np.mean(local_accuracy_average))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('MLP Accuracy vs. Number of Iterations (10-fold CV)')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final running stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Calculate the neurons configuration, based on requirements provided by the professor\n",
    "best_max_iter = 300\n",
    "best_neuron_length = 387\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "accuracies = []\n",
    "\n",
    "# Perform 10-fold CV for each neuron that I'm evaluating\n",
    "for learning_rate in learning_rates:\n",
    "    print(\"Entering learning rate amount of:\", learning_rate)\n",
    "    local_accuracy_average = []\n",
    "    for train_index, test_index in kf.split(sentiments_features):\n",
    "        sentiments_train, sentiments_test = sentiments_features[train_index], sentiments_features[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(best_neuron_length,), max_iter=best_max_iter, learning_rate_init=learning_rate, activation='relu', solver='adam', random_state=42)\n",
    "        mlp.fit(sentiments_train, labels_train)\n",
    "        labels_predict = mlp.predict(sentiments_test)\n",
    "        local_accuracy_average.append(accuracy_score(labels_test, labels_predict))\n",
    "    print(\"Processed learning rate with 10-fold cross-validation, average accuracy:\", np.mean(local_accuracy_average))\n",
    "    accuracies.append(np.mean(local_accuracy_average))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('MLP Accuracy vs. Learning Rate (10-fold CV)')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for parameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Percentage test split method - can adjust percentage\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# The parameters we will pass to GridSearch\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(450,),(387,),(400,)],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'random_state': [1,50],\n",
    "    'max_iter': [300]\n",
    "}\n",
    "\n",
    "# Create MLPClassifier object\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "\n",
    "# Setting up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=3,verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fitting GridSearchCV\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# Best parameters found by GridSearchCV\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model found from the grid search\n",
    "best_mlp = grid_search.best_estimator_\n",
    "y_pred = best_mlp.predict(test_features)\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print(\"Accuracy of the best model: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP With the Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "datasets_to_explore = ['datasets/twitter_sentiment_base_ready.csv', 'datasets/twitter_sentiments_base_sampled.csv', 'datasets/twitter_sentiment_base_decision_tree.csv', 'datasets/twitter_sentiment_base_pca.csv']\n",
    "\n",
    "# Define the KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#best_max_iter = 300\n",
    "#best_neuron_length = 387\n",
    "#best_learning_rate = 0.001\n",
    "\n",
    "best_max_iter = 300\n",
    "best_neuron_length = 387\n",
    "best_learning_rate = 0.01\n",
    "\n",
    "for dataset in datasets_to_explore:\n",
    "    print('Entering dataset ' + dataset)\n",
    "    working_base = pd.read_csv(dataset)\n",
    "    sentiments_features = working_base.loc[:, working_base.columns.str.startswith('feature_')].to_numpy()\n",
    "    labels = working_base['label'].to_numpy()\n",
    "    accuracies = []\n",
    "\n",
    "    # Perform 10-fold CV\n",
    "    for train_index, test_index in kf.split(sentiments_features):\n",
    "        sentiments_train, sentiments_test = sentiments_features[train_index], sentiments_features[test_index]\n",
    "        labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(best_neuron_length,), max_iter=best_max_iter, learning_rate_init=best_learning_rate, activation='relu', solver='sgd', random_state=42)\n",
    "        mlp.fit(sentiments_train, labels_train)\n",
    "        labels_predict = mlp.predict(sentiments_test)\n",
    "        accuracies.append(accuracy_score(labels_test, labels_predict))\n",
    "    \n",
    "    content = 'Dataset: ' + dataset + ', 10-Fold CV Average Accuracy: ' + str(np.mean(accuracies))\n",
    "    print(content)\n",
    "    with open('datasets/results_grid.txt', \"a\") as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "\n",
    "We're now going to evaluate how a few unsupervised machine learning algorithms work, gettings started with the k-Means. We will vary the amount of iterations to try to find the best parameters for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "db_scores = []\n",
    "silhouette_scores = []\n",
    "k_values = range(2, 21)\n",
    "\n",
    "for k in k_values:\n",
    "    # Helper variables for calculating the average score after running the algorithm 5 times\n",
    "    current_db_scores = []\n",
    "    current_silhouette_scores = []\n",
    "    for seed in range(5):\n",
    "        print(f\"Entering k={k} iteration of the K-Means, iteration number { seed }.\")\n",
    "        # Runs K-Means 5 times for the current K iteration\n",
    "        kmeans = KMeans(n_clusters=k, random_state=seed, n_init=1)\n",
    "        labels = kmeans.fit_predict(sentiments_features)\n",
    "        # Calculate the scores of interest\n",
    "        db_score = davies_bouldin_score(sentiments_features, labels)\n",
    "        silhouette_grade = silhouette_score(sentiments_features, labels)\n",
    "        current_db_scores.append(db_score)\n",
    "        current_silhouette_scores.append(silhouette_grade)\n",
    "    # Calculate the scores for the current K\n",
    "    db_scores.append(np.mean(current_db_scores))\n",
    "    silhouette_scores.append(np.mean(current_silhouette_scores))\n",
    "    print(f\"Average Davies-Bouldin Score for k={k}: {np.mean(current_db_scores)}\")\n",
    "    print(f\"Average Silhouette Score for k={k}: {np.mean(current_silhouette_scores)}\")\n",
    "    with open('datasets/results_k_means.txt', \"a\") as file:\n",
    "        file.write(f\"Average Davies-Bouldin Score for k={k}: {np.mean(current_db_scores)}\")\n",
    "        file.write(f\"Average Silhouette Score for k={k}: {np.mean(current_silhouette_scores)}\")\n",
    "\n",
    "# Plotting results\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Average Davies-Bouldin Score', color=color)\n",
    "ax1.plot(k_values, db_scores, marker='o', linestyle='-', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "'''ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Average Silhouette Score', color=color)\n",
    "ax2.plot(k_values, silhouette_scores, marker='o', linestyle='-', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)'''\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.title('Clustering Performance Evaluation')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "Implementing this unsupervised machine learning method and then varying the parameters to find the best configuration available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Range of k values to test\n",
    "k_values = range(2, 21)\n",
    "db_scores = []\n",
    "silhouette_scores = []\n",
    "\n",
    "# Agglomerative Clustering without specifying the number of clusters\n",
    "clustering = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage='ward')\n",
    "clustering.fit(sentiments_features)\n",
    "\n",
    "# Extracting the number of clusters and their labels at different cuts of the dendrogram\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Generate the linkage matrix\n",
    "Z = linkage(sentiments_features, method='ward')\n",
    "\n",
    "for k in k_values:\n",
    "    # Cutting the dendrogram at the specified number of clusters\n",
    "    labels = fcluster(Z, k, criterion='maxclust')\n",
    "    \n",
    "    # Calculate and store the Davies-Bouldin score\n",
    "    db_score = davies_bouldin_score(sentiments_features, labels)\n",
    "    db_scores.append(db_score)\n",
    "    \n",
    "    # Calculate and store the Silhouette score\n",
    "    silhouette = silhouette_score(sentiments_features, labels)\n",
    "    silhouette_scores.append(silhouette)\n",
    "    \n",
    "    print(f\"Number of clusters: {k}\")\n",
    "    print(f\"Davies-Bouldin Score: {db_score}\")\n",
    "    print(f\"Silhouette Score: {silhouette}\")\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_values, db_scores, marker='o', linestyle='-', color='red')\n",
    "plt.title('Davies-Bouldin Score vs. Number of Clusters')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Davies-Bouldin Score')\n",
    "plt.grid(True)\n",
    "\n",
    "'''\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_values, silhouette_scores, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Silhouette Score vs. Number of Clusters')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)'''\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why distance_threshold=0 and n_clusters=None?\n",
    "\n",
    "By setting n_clusters=None and distance_threshold=0, we instruct AgglomerativeClustering to not stop merging clusters at a particular number of clusters or a specific distance threshold. Instead, it continues merging clusters until all points are merged into a single cluster, building the complete hierarchy or dendrogram. This full dendrogram captures all possible mergings from each point being its own cluster to all points being in one cluster.\n",
    "\n",
    "Once the full dendrogram is constructed, we can efficiently \"cut\" the dendrogram at different levels (different values of k) to explore the structure of the data without having to re-run the clustering algorithm each time. This is much more efficient than re-instantiating and re-running the AgglomerativeClustering for each k, especially for large datasets.\n",
    "\n",
    "If we were to instantiate AgglomerativeClustering within the loop for each k, it would mean recalculating the same hierarchical relationships multiple times: one for each value of k. This recalculating is unnecessary because the hierarchical relationships between data points don't change as k changes; only the level at which we decide to \"cut\" the tree changes.\n",
    "\n",
    "Finally, by generating the full dendrogram once, we capture all possible clustering configurations. We can then efficiently explore different configurations by adjusting where you cut the dendrogram. This is particularly useful for exploratory data analysis, where we might not know in advance what the optimal number of clusters should be and want to examine various possibilities quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "# Cluster using K-Means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42).fit(sentiments_features)\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Cluster using Hierarchical Clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=2).fit(sentiments_features)\n",
    "hierarchical_labels = hierarchical.labels_\n",
    "\n",
    "# Calculate metrics for K-Means\n",
    "silhouette_kmeans = silhouette_score(sentiments_features, kmeans_labels)\n",
    "db_index_kmeans = davies_bouldin_score(sentiments_features, kmeans_labels)\n",
    "\n",
    "# Calculate metrics for Hierarchical Clustering\n",
    "silhouette_hierarchical = silhouette_score(sentiments_features, hierarchical_labels)\n",
    "db_index_hierarchical = davies_bouldin_score(sentiments_features, hierarchical_labels)\n",
    "\n",
    "# Output the results\n",
    "print(\"K-Means Silhouette Score:\", silhouette_kmeans)\n",
    "print(\"Hierarchical Silhouette Score:\", silhouette_hierarchical)\n",
    "print(\"K-Means Davies-Bouldin Index:\", db_index_kmeans)\n",
    "print(\"Hierarchical Davies-Bouldin Index:\", db_index_hierarchical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test_splits = [0.3, 0.2, 0.1]\n",
    "n_values = [10, 20]\n",
    "estimators = [ MLPClassifier(max_iter=300, hidden_layer_sizes=(387,), activation='relu', solver='adam', random_state=42) ] # KNeighborsClassifier(), GaussianNB(), MLPClassifier(max_iter=300, hidden_layer_sizes=(387,))]\n",
    "max_features = [0.3, 0.5, 0.8]\n",
    "\n",
    "# Holdout strategy (10/90, 20/80, 30/70)\n",
    "for test_split in test_splits:\n",
    "    for estimator in estimators:\n",
    "        for max_feature in max_features:\n",
    "            for n in n_values:\n",
    "                train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=test_split, random_state=42)\n",
    "                bagging = BaggingClassifier(estimator=estimator, max_features=max_feature, n_estimators=n, random_state=42)\n",
    "                bagging.fit(train_features, train_labels)\n",
    "                labels_predict = bagging.predict(test_features)\n",
    "                accuracy = accuracy_score(test_labels, labels_predict)\n",
    "                display_message = f\"Accuracy of Bagging Classifier ({estimator} as the Base Estimator) with {n} estimators, { max_feature } max features and {test_split} test split: {accuracy}\"\n",
    "                print(display_message)\n",
    "                with open('datasets/bagging_accuracies.txt', \"a\") as file:\n",
    "                    file.write(display_message + \"\\n\")\n",
    "\n",
    "# Cross-validation strategy\n",
    "for estimator in estimators:\n",
    "    for max_feature in max_features:\n",
    "        for n in n_values:\n",
    "            bagging = BaggingClassifier(estimator=estimator, max_features=max_feature, n_estimators=n, random_state=42)\n",
    "            scores = cross_val_score(bagging, sentiments_features, labels, cv=10, scoring='accuracy')\n",
    "            mean_accuracy = np.mean(scores)\n",
    "            display_message = f\"10-fold CV Accuracy of Bagging Classifier ({type(estimator).__name__} as the Base Estimator) with {n} estimators and { max_feature } max features: {mean_accuracy}\"\n",
    "            print(display_message)\n",
    "            with open('datasets/bagging_accuracies.txt', \"a\") as file:\n",
    "                file.write(display_message + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Wrapper for KNeighborsClassifier to ignore sample_weight\n",
    "class KNeighborsClassifierWrapper(KNeighborsClassifier):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return super().fit(X, y)\n",
    "\n",
    "# Wrapper for GaussianNB to ignore sample_weight\n",
    "class GaussianNBWrapper(GaussianNB):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return super().fit(X, y)\n",
    "\n",
    "# Wrapper for MLPClassifier to ignore sample_weight\n",
    "class MLPClassifierWrapper(MLPClassifier):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return super().fit(X, y)\n",
    "\n",
    "test_splits = [0.3, 0.2, 0.1]\n",
    "n_estimators = [10, 20]\n",
    "estimators = [\n",
    "    DecisionTreeClassifier(),\n",
    "    KNeighborsClassifierWrapper(),\n",
    "    GaussianNBWrapper(),\n",
    "    MLPClassifierWrapper(max_iter=300, hidden_layer_sizes=(387,))\n",
    "]\n",
    "\n",
    "# Assuming sentiments_features and labels are defined and preprocessed\n",
    "# Holdout strategy (10/90, 20/80, 30/70)\n",
    "for test_split in test_splits:\n",
    "    for estimator in estimators:\n",
    "        for n in n_estimators:\n",
    "            train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=test_split, random_state=42)\n",
    "            adaBooster = AdaBoostClassifier(estimator=estimator, n_estimators=n, algorithm=\"SAMME\", random_state=42)\n",
    "            adaBooster.fit(train_features, train_labels)\n",
    "            labels_predict = adaBooster.predict(test_features)\n",
    "            accuracy = accuracy_score(test_labels, labels_predict)\n",
    "            display_message = f\"Accuracy of ADA Boosting ({estimator.__class__.__name__} as the Base Estimator) with {n} estimators and {test_split} test split: {accuracy}\"\n",
    "            print(display_message)\n",
    "            with open('datasets/boosting_accuracies.txt', \"a\") as file:\n",
    "                file.write(display_message + \"\\n\")\n",
    "\n",
    "# Cross-validation strategy\n",
    "for estimator in estimators:\n",
    "    for n in n_estimators:\n",
    "        adaBooster = AdaBoostClassifier(estimator=estimator, n_estimators=n, algorithm=\"SAMME\", random_state=42)\n",
    "        scores = cross_val_score(adaBooster, sentiments_features, labels, cv=10, scoring='accuracy')\n",
    "        mean_accuracy = np.mean(scores)\n",
    "        display_message = f\"10-fold CV Accuracy of ADA Boosting ({type(estimator).__name__} as the Base Estimator) with {n} estimators: {mean_accuracy}\"\n",
    "        print(display_message)\n",
    "        with open('datasets/boosting_accuracies.txt', \"a\") as file:\n",
    "            file.write(display_message + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test_splits = [0.3, 0.2, 0.1]\n",
    "criterions = ['gini', 'entropy', 'log_loss']\n",
    "n_estimators = [10, 100]\n",
    "\n",
    "# Holdout strategy (10/90, 20/80, 30/70)\n",
    "for test_split in test_splits:\n",
    "    for criterion in criterions:\n",
    "        for n in n_estimators:\n",
    "            train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=test_split, random_state=42)\n",
    "            randomForest = RandomForestClassifier(criterion=criterion, n_estimators=n, random_state=42)\n",
    "            randomForest.fit(train_features, train_labels)\n",
    "            labels_predict = randomForest.predict(test_features)\n",
    "            accuracy = accuracy_score(test_labels, labels_predict)\n",
    "            display_message = f\"Accuracy of Random Forest Classifier with {n} estimators, { criterion } criterion and {test_split} test split: {accuracy}\"\n",
    "            print(display_message)\n",
    "            with open('datasets/random_forest_accuracies.txt', \"a\") as file:\n",
    "                file.write(display_message + \"\\n\")\n",
    "\n",
    "# Cross-validation strategy\n",
    "for criterion in criterions:\n",
    "    for n in n_estimators:\n",
    "        randomForest = RandomForestClassifier(criterion=criterion, n_estimators=n, random_state=42)\n",
    "        scores = cross_val_score(randomForest, sentiments_features, labels, cv=10, scoring='accuracy')\n",
    "        mean_accuracy = np.mean(scores)\n",
    "        display_message = f\"10-fold CV Accuracy of Random Forest Classifier with {n} estimators and { criterion } criterion: {mean_accuracy}\"\n",
    "        print(display_message)\n",
    "        with open('datasets/random_forest_accuracies.txt', \"a\") as file:\n",
    "            file.write(display_message + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test_splits = [0.3, 0.2, 0.1]\n",
    "base_estimators_10 = [('MLP01', MLPClassifier(hidden_layer_sizes=(10), max_iter=1000)),\n",
    "                      ('MLP02', MLPClassifier(hidden_layer_sizes=(8), max_iter=1000)),\n",
    "                      ('MLP03', MLPClassifier(hidden_layer_sizes=(6), max_iter=1000)),\n",
    "                      ('MLP04', MLPClassifier(hidden_layer_sizes=(4), max_iter=1000)),\n",
    "                      ('MLP05', MLPClassifier(hidden_layer_sizes=(2), max_iter=1000)),\n",
    "                      ('kNN01', KNeighborsClassifier(n_neighbors=1)),\n",
    "                      ('kNN02', KNeighborsClassifier(n_neighbors=2)),\n",
    "                      ('kNN03', KNeighborsClassifier(n_neighbors=3)),\n",
    "                      ('kNN04', KNeighborsClassifier(n_neighbors=4)),\n",
    "                      ('kNN05', KNeighborsClassifier(n_neighbors=5))]\n",
    "base_estimators_20 = base_estimators_10 + [('MLP06', MLPClassifier(hidden_layer_sizes=(12), max_iter=1000)),\n",
    "                                           ('MLP07', MLPClassifier(hidden_layer_sizes=(14), max_iter=1000)),\n",
    "                                           ('MLP08', MLPClassifier(hidden_layer_sizes=(16), max_iter=1000)),\n",
    "                                           ('MLP09', MLPClassifier(hidden_layer_sizes=(18), max_iter=1000)),\n",
    "                                           ('MLP10', MLPClassifier(hidden_layer_sizes=(20), max_iter=1000)),\n",
    "                                           ('kNN06', KNeighborsClassifier(n_neighbors=6)),\n",
    "                                           ('kNN07', KNeighborsClassifier(n_neighbors=7)),\n",
    "                                           ('kNN08', KNeighborsClassifier(n_neighbors=8)),\n",
    "                                           ('kNN09', KNeighborsClassifier(n_neighbors=9)),\n",
    "                                           ('kNN10', KNeighborsClassifier(n_neighbors=10))]\n",
    "base_estimators = [base_estimators_10, base_estimators_20]   \n",
    "\n",
    "# Holdout strategy (10/90, 20/80, 30/70)\n",
    "for test_split in test_splits:\n",
    "    for base_estimator in base_estimators:\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(sentiments_features, labels, test_size=test_split, random_state=42)\n",
    "        stacking = StackingClassifier(estimators=base_estimator)\n",
    "        stacking.fit(train_features, train_labels)\n",
    "        labels_predict = stacking.predict(test_features)\n",
    "        accuracy = accuracy_score(test_labels, labels_predict)\n",
    "        display_message = f\"Accuracy of Stacking Classifier with { len(base_estimator) } base estimators and {test_split} test split: {accuracy}\"\n",
    "        print(display_message)\n",
    "        with open('datasets/stacking_accuracies.txt', \"a\") as file:\n",
    "            file.write(display_message + \"\\n\")\n",
    "\n",
    "# Cross-validation strategy\n",
    "for base_estimator in base_estimators:\n",
    "    stacking = StackingClassifier(estimators=base_estimator)\n",
    "    scores = cross_val_score(stacking, sentiments_features, labels, cv=10, scoring='accuracy')\n",
    "    mean_accuracy = np.mean(scores)\n",
    "    display_message = f\"10-fold CV Accuracy of Stacking Classifier with { len(base_estimator) } estimators: {mean_accuracy}\"\n",
    "    print(display_message)\n",
    "    with open('datasets/stacking_accuracies.txt', \"a\") as file:\n",
    "        file.write(display_message + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State of the Art for Sentiment Analysis: BERT Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "dataset = pd.read_csv(\"datasets/twitter_sentiment_base_original.csv\", usecols=[\"text\", \"label\"])\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(example['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "tokenized_data = dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = tokenized_data.train_test_split(test_size=0.3, stratify_by_column='label').values()\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./datasets', \n",
    "    num_train_epochs=3, \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500, \n",
    "    weight_decay=0.01, \n",
    "    logging_dir='./datasets/logs', \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=train_data, \n",
    "    eval_dataset=test_data,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate model\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this block when you want to import the data from previously saved datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "working_base = pd.read_csv('datasets/twitter_sentiment_base_ready_reduced.csv')\n",
    "sentiments_features = working_base.loc[:, working_base.columns.str.startswith('feature_')].to_numpy()\n",
    "labels = working_base['label'].to_numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
